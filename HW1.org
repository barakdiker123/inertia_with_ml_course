#+title: Homework 1
* COMMENT Finding the bias scale-factors miss-align errors

Our model of errors is

\begin{equation*}
\tilde{f} = (I_3+S_a+M_a)f+b_a+w_a 
\end{equation*}
Where
\begin{math}
S_a\in diag_{3\times 3}\mathbb{R}
\end{math}
and 
\begin{math}
M_a\in AntiSymm_{3\times 3}\mathbb{R}
\end{math}
and
\begin{math}
b_a\in \mathbb{R}^3
\end{math}

For Estimating the bias vector \(b_a\), I'll use the following derivation

\begin{equation*}
\tilde{f} = (I_3+S_a+M_a)0_{3\times 1}+b_a+w_a 
\end{equation*}
which implies given \(\mathbb{E}w_a=0_{3\times 1}\) that

\begin{equation*}
\tilde{f} = b_a +w_a
\end{equation*}

So given a sequence \( (\tilde{f}_{i})_{i=1}^{n} \) where \(n\in\mathbb{N}\) is the sample size,
I'll estimate \(b_a\) with the following estimator

\begin{equation*}
\sum_{i=1}^nb_a = \sum_{i=1}^n\tilde{f}_{i} + \sum_{i=1}^nw_a
\end{equation*}
and then
\begin{equation*}
\frac{1}{n}\sum_{i=1}^nb_a = \frac{1}{n}\sum_{i=1}^n\tilde{f}_{i} + \frac{1}{n}\sum_{i=1}^nw_a
\end{equation*}
and the final Estimator is 
\begin{equation*}
b_a = \frac{1}{n}\sum_{i=1}^n\tilde{f}_{i} 
\end{equation*}


#+begin_src python :exports both :results output
import pandas as pd
df = pd.read_csv('./dataset_work/sec300xminus.csv')
print(df[:2])
print(df['gFx'][:2])
#print("a")
#+end_src

#+RESULTS:
:        time     gFx     gFy     gFz    TgF
: 0  0.003471 -0.9765 -0.0024  0.2323  1.004
: 1  0.003909 -0.9762 -0.0022  0.2328  1.004
: 0   -0.9765
: 1   -0.9762
: Name: gFx, dtype: float64
* Finding the Bias Scale-Factor miss align errors 



Our model of errors is
\label{equ:1}
\begin{equation}
\tilde{f} = (I_3+S_a+M_a)f+b_a+w_a 
\end{equation}
Where
\begin{math}
S_a\in diag_{3\times 3}\mathbb{R}
\end{math}
and 
\begin{math}
M_a\in AntiSymm_{3\times 3}\mathbb{R}
\end{math}
and
\begin{math}
b_a\in \mathbb{R}^3
\end{math}

Note the following derivation

\begin{equation*}
\tilde{f}-f = (S_a+M_a)f+b_a
\end{equation*}
Concating the following matrices would generate the following matrix 
\begin{equation*}
M_{3\times 4}=
\left[
\begin{array}{c | c}
M_a+S_a & b_a
\end{array}
\right]
\end{equation*}

Given that \(M_{3\times 4}\) matrix we can simplify equation \ref{equ:1}
to be

\begin{equation*}
\tilde{f} - f_{3\times 1 } = M_{3\times 4}
\begin{pmatrix}
f_{3\times 1 } \\ 1 
\end{pmatrix}
\end{equation*}

For example, Estimating left column of M with down x direction measurements
\begin{equation*}
\tilde{f}_{down}^x-
\begin{pmatrix}
-g \\ 0 \\ 0 
\end{pmatrix} = M
\begin{pmatrix}
-g \\ 0 \\ 0 \\ 1
\end{pmatrix}
\end{equation*}


We can concate all the vector equations together and we'll infer the following matrix equation

\begin{equation*}
\begin{pmatrix}
\tilde{f}_{down}^{x} & \tilde{f}_{x}^{up} & \cdots & \tilde{f}_{up}^{z} 
\end{pmatrix}
-
\begin{pmatrix}
-g & g  & 0 & 0 & 0 &   0 \\
0 & 0 & -g & g & 0  & 0 \\
0 & 0 & 0 & 0  & -g & g
\end{pmatrix}
=M
\begin{pmatrix}
-g & g  &  0 & 0 & 0 & 0 \\ 
0 & 0  &  -g & g & 0  & 0 \\ 
0 & 0  &  0 & 0 & -g  & g \\ 
1 & 1 &  1 & 1 & 1 &1 \\ 
\end{pmatrix}
\end{equation*}

I'll denote the matrix \(A \in \mathbb{R}^{4\times 6 }\) like so 

\begin{equation*}
A_{4\times 6}=\begin{pmatrix}
-g & g  &  0 & 0 & 0 & 0 \\ 
0 & 0  &  -g & g & 0  & 0 \\ 
0 & 0  &  0 & 0 & -g  & g \\ 
1 & 1 &  1 & 1 & 1 &1 \\ 
\end{pmatrix}
\end{equation*}


and

\begin{equation*}
z_{3\times 6}=M_{3\times 4 }A_{4\times 6}
\end{equation*}

\begin{equation*}
z_{3\times 6}A^{T}(AA^{T})^{-1}=M_{3\times 4 }A_{4\times 6}A^{T}(AA^{T})^{-1}
\end{equation*}


\begin{equation}\label{eq:LS}
z_{3\times 6}A^{T}(AA^{T})^{-1}=M_{3\times 4 }
\end{equation}

Equation \ref{eq:LS} gives us the best \(M\) matrix for a given measurement
so our estimator is an \bold{Unbiased estimator}, so for simple calculation we'll have


\begin{equation}\label{eq:LS2}
\hat{M}=\frac{1}{n}\sum_{i=1}^{n}M = \frac{1}{n}\sum_{i=1}^{n}z_{3\times 6}A^{T}(AA^{T})^{-1}
\end{equation}


* Implementation
Here I am calculating the Matrix A of equation \ref{eq:LS} using the Following code 
#+begin_src python :results output :exports both
# Calculating A 
import numpy as np
#g = 9.81 #m/s^2
g =1 
D = np.zeros((3,6))
D[0,0] = -g ; D[0,1] = g ; D[1,2] = -g ; D[1,3] = g ; D[2,4] =-g ; D[2,5]=g
E = np.ones((1,6),dtype=float)
print("A=")
print(np.vstack((D,E)))
#+end_src

#+RESULTS:
: A=
: [[-1.  1.  0.  0.  0.  0.]
:  [ 0.  0. -1.  1.  0.  0.]
:  [ 0.  0.  0.  0. -1.  1.]
:  [ 1.  1.  1.  1.  1.  1.]]

#+name: A
| -9.81 | 9.81 |    0. |   0. |    0. |   0. |
|    0. |   0. | -9.81 | 9.81 |    0. |   0. |
|    0. |   0. |    0. |   0. | -9.81 | 9.81 |
|    1. |   1. |    1. |   1. |    1. |   1. |

#+name: B
| -1. | 1. |  0. | 0. |  0. | 0. |
|  0. | 0. | -1. | 1. |  0. | 0. |
|  0. | 0. |  0. | 0. | -1. | 1. |
|  1. | 1. |  1. | 1. |  1. |  1 |


** COMMENT comment 

#+begin_src python :results value :exports both :var A=A
import numpy as np
A = np.array(A)
#M  = @ np.transpose(A) @ np.linalg.inv(A@np.transpose(A))
return A.shape
#+END_SRC

#+RESULTS:
| 4 | 6 |

\pagebreak
** Core implementation
Here I am finding the errors as I have developed in the theory section

In the end I'll obtain the matrix \(M\in \mathbb{R}^{3\times 4}\) which consist of \(b_a,S_a,M_a\)

#+begin_src python :results output :exports both :var A=B
import numpy as np
import pandas as pd
x_mi = pd.read_csv("./dataset_work/sec300xminus.csv")
y_mi = pd.read_csv("./dataset_work/sec300yminus.csv")
z_mi = pd.read_csv("./dataset_work/sec300zminus.csv")
x_pl = pd.read_csv("./dataset_work/sec300xplus.csv")
y_pl = pd.read_csv("./dataset_work/sec300yplus.csv")
z_pl = pd.read_csv("./dataset_work/sec300zplus.csv")
x_mi = x_mi[['gFx','gFy','gFz']].to_numpy()
y_mi = y_mi[['gFx','gFy','gFz']].to_numpy()
z_mi = z_mi[['gFx','gFy','gFz']].to_numpy()
x_pl = x_pl[['gFx','gFy','gFz']].to_numpy()
y_pl = y_pl[['gFx','gFy','gFz']].to_numpy()
z_pl = z_pl[['gFx','gFy','gFz']].to_numpy()
A = np.array(A)

x_mi -= np.array([-1,0,0])
y_mi -= np.array([0,-1,0])
z_mi -= np.array([0,0,-1])
x_pl -= np.array([1,0,0])
y_pl -= np.array([0,1,0])
z_pl -= np.array([0,0,1])

    
n=0 
sum_of_M = np.zeros((3,4))
for x_m,y_m,z_m,x_p,y_p,z_p in zip(x_mi,y_mi,z_mi,x_pl,y_pl,z_pl):
    n+=1
    x_m = np.expand_dims(x_m,1).T
    y_m = np.expand_dims(y_m,1).T
    z_m = np.expand_dims(z_m,1).T
    x_p = np.expand_dims(x_p,1).T
    y_p = np.expand_dims(y_p,1).T
    z_p = np.expand_dims(z_p,1).T
    z= np.concatenate((x_m,x_p,y_m,y_p,z_m,z_p)).T
    M  = z @ np.transpose(A) @ np.linalg.inv(A@np.transpose(A))
    sum_of_M += M
    #break
esti_M = sum_of_M/n #, sum_of_M.shape
print("The Estimated M which is unbiased estimator is \n",esti_M)
print("The S_a error is \n", np.diag((esti_M[0,0],esti_M[1,1],esti_M[2,2])))
M_a = esti_M.copy()
M_a = M_a[0:3,0:3]
M_a[0,0] = 0
M_a[1,1] = 0
M_a[2,2] = 0
print("The M_a error is \n", M_a)
print("The Bias of IMU is \n", esti_M[:,3])

#return sum_of_M.shape
#return sum_of_M/n #, sum_of_M.shape
#return  x_minus[['gFx','gFy','gFz']].to_numpy().shape[0]
#return x_minus[['gFx','gFy','gFz']].to_numpy().shape
#+END_SRC

#+RESULTS:
#+begin_example
The Estimated M which is unbiased estimator is 
 [[-0.02861075 -0.00391678 -0.01046105 -0.00122523]
 [ 0.00165313 -0.00751652 -0.00525399  0.0009181 ]
 [ 0.02379594 -0.02749688 -0.00575567  0.13867218]]
The S_a error is 
 [[-0.02861075  0.          0.        ]
 [ 0.         -0.00751652  0.        ]
 [ 0.          0.         -0.00575567]]
The M_a error is 
 [[ 0.         -0.00391678 -0.01046105]
 [ 0.00165313  0.         -0.00525399]
 [ 0.02379594 -0.02749688  0.        ]]
The Bias of IMU is 
 [-0.00122523  0.0009181   0.13867218]
#+end_example
* 2.6 Only bias error
In this exercise, I take only one accelerometer and consider only the bias error

for this derivation I'll consider the following equation \ref{equ:1}

\begin{equation*}
\tilde{f} = (I_3+S_a+M_a)f+b_a+w_a 
\end{equation*}

And if I am assuming only bias error, I'll have the following equation


\begin{equation}\label{equ:bias}
\tilde{f} = f+b_a 
\end{equation}
and for estimating equation \ref{equ:bias} , consider

\begin{equation}
b_a = \tilde{f}-f 
\end{equation}

which is an "unbiased estimator"

\begin{equation}
\hat{b}_a = \frac{1}{n} \sum_{i=0}^{n} b_a = \frac{1}{n} \sum_{i=0}^{n}(\tilde{f}-f )
\end{equation}




#+begin_src python :results output :exports both :var A=A
import numpy as np
import pandas as pd
x_mi = pd.read_csv("./dataset_work/sec300xminus.csv")
x_mi = x_mi[['gFx','gFy','gFz']].to_numpy()
diff_x = x_mi-np.array([-1 , 0, 0])
print("The bias of the accelerometer using average is \n")
print(diff_x.sum(axis=0) / diff_x.shape[0])
print(diff_x.shape[0])
#+end_src

#+RESULTS:
: [ 0.02406121 -0.00294848  0.23269958]
: 149878
\newpage
* 2.7 calculate the bias errors using only average
In order to do so I'll Implement 2.6 for all accelerometer 

#+begin_src python :results output :exports both :var A=A
import numpy as np
import pandas as pd
def estimate_only_bias(address= "./dataset_work/sec300xminus.csv",true_force = [-1,0,0]): # true_force = [-1,0,0]
    x_mi = pd.read_csv(address)
    x_mi = x_mi[['gFx','gFy','gFz']].to_numpy()
    diff_x = x_mi-np.array(true_force)
    return diff_x.sum(axis=0) / diff_x.shape[0]

bias_term = estimate_only_bias("./dataset_work/sec300xminus.csv",[-1,0,0])
bias_term += estimate_only_bias("./dataset_work/sec300yminus.csv",[0,-1,0])
bias_term += estimate_only_bias("./dataset_work/sec300zminus.csv",[0,0,-1])
bias_term += estimate_only_bias("./dataset_work/sec300xplus.csv",[1,0,0])
bias_term += estimate_only_bias("./dataset_work/sec300yplus.csv",[0,1,0])
bias_term += estimate_only_bias("./dataset_work/sec300zplus.csv",[0,0,1])
print("The bias error using only averages is ")
print(bias_term/6)
#+end_src

#+RESULTS:
: The bias error using only averages is 
: [-0.00119208  0.00093832  0.13886594]


** Special note 
  using the Entire error model the bias is very close to the average bias 
  
- The Bias of IMU using entire model  is 
 [-0.00122523  0.0009181   0.13867218]
- The Bias of IMU using only average is
 [-0.00119208  0.00093832  0.13886594]
** Important conclusions 
Given our entire error model lets see how well the error model fits the data by plotting the error which will be defined by \( |f - \tilde{f}|_2\) lets see how It'll look like 


our calculated \(M_{3\times 4}\) matrix is 
#+name: M
| -0.02861075 | -0.00391678 | -0.01046105 | -0.00122523 |
|  0.00165313 | -0.00751652 | -0.00525399 |   0.0009181 |
|  0.02379594 | -0.02749688 | -0.00575567 |  0.13867218 |


#+begin_src python :results output :exports both :var M=M
import numpy as np
import sys
import pandas as pd
from matplotlib import pyplot as plt 
x_mi = pd.read_csv("./dataset_work/sec300xminus.csv")
y_mi = pd.read_csv("./dataset_work/sec300yminus.csv")
z_mi = pd.read_csv("./dataset_work/sec300zminus.csv")
x_pl = pd.read_csv("./dataset_work/sec300xplus.csv")
y_pl = pd.read_csv("./dataset_work/sec300yplus.csv")
z_pl = pd.read_csv("./dataset_work/sec300zplus.csv")
x_mi = x_mi[['gFx','gFy','gFz']].to_numpy()
y_mi = y_mi[['gFx','gFy','gFz']].to_numpy()
z_mi = z_mi[['gFx','gFy','gFz']].to_numpy()
x_pl = x_pl[['gFx','gFy','gFz']].to_numpy()
y_pl = y_pl[['gFx','gFy','gFz']].to_numpy()
z_pl = z_pl[['gFx','gFy','gFz']].to_numpy()
#A = np.array(A)
M = np.array(M)
M = M + np.concatenate([ np.identity(3) , np.array([[0,0,0]]).T],axis=1)
x_mi_improved =x_mi -  M @ np.array([-1,0,0,1])
x_mi_usual =x_mi -  np.array([-1,0,0])
y_mi_improved =y_mi -   M@np.array([0,-1,0,1])
y_mi_usual =y_mi -  np.array([0,-1,0])
z_mi -=M@np.array([0,0,-1,1])
#x_pl -=M@np.array([1,0,0,1])
x_pl_improved = x_pl - M @np.array([1,0,0,1])
x_pl_usual = x_pl - np.array([1,0,0])
#print(np.linalg.norm(x_pl_usual[30]))
y_pl -=M@np.array([0,1,0,1])
z_pl -=M@np.array([0,0,1,1])

x_mi_improved = np.array([np.linalg.norm(v) for v in x_mi_improved]).reshape(-1)
x_mi_usual = np.array([np.linalg.norm(v) for v in x_mi_usual]).reshape(-1)

y_mi_improved = np.array([np.linalg.norm(v) for v in y_mi_improved]).reshape(-1)
y_mi_usual = np.array([np.linalg.norm(v) for v in y_mi_usual]).reshape(-1)
x_pl_improved = np.array([np.linalg.norm(v) for v in x_pl_improved]).reshape(-1)
x_pl_usual = np.array([np.linalg.norm(v) for v in x_pl_usual]).reshape(-1)
#print(x_mi[:3])
fig, ax = plt.subplots(3,1,figsize=(5,10))
ax[0].set_title("x minus before and after calibration")
ax[0].plot(np.arange(len(x_mi[:200])),x_mi_improved[:200],'+',label='After Calibration')
ax[0].plot(np.arange(len(x_mi[:200])),x_mi_usual[:200],label='Before calibration')
ax[0].legend()
ax[1].set_title("y minus before and after calibration")
ax[1].plot(np.arange(len(y_mi[:200])),y_mi_improved[:200],'+',label='After Calibration')
ax[1].plot(np.arange(len(y_mi[:200])),y_mi_usual[:200],label='Before calibration')
ax[1].legend()
ax[2].set_title("x plus before and after calibration")
ax[2].plot(np.arange(len(x_pl[:200])),x_pl_improved[:200],'+',label='After Calibration')
ax[2].plot(np.arange(len(x_pl[:200])),x_pl_usual[:200],label='Before calibration')
ax[2].legend()
plt.xlabel("Sample[1]")
plt.ylabel("Error in eulidean norm[g]")
plt.ylim(-0.001,0.3)
plt.savefig('error_fixed_unfixed.png')
#plt.show()
    
#+end_src

#+RESULTS:


[[./error_fixed_unfixed.png]]






